{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhattm/.conda/envs/tomodl/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "from segment2d import *\n",
    "import nibabel as nib\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "# import albumentations as A\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import kornia as K\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "# natsort\n",
    "from natsort import natsorted\n",
    "# import SimpleITK as sitk\n",
    "from segment2d import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_image_normal = natsorted(glob.glob(\"./emidec-dataset-1.0.1/Case_N*/I*/*\"))\n",
    "list_image_pathologic = natsorted(glob.glob(\"./emidec-dataset-1.0.1/Case_P*/I*/*\"))\n",
    "# split the dataset into training and validation and test with sample ratio 70:10:20\n",
    "random.seed(42)\n",
    "random.shuffle(list_image_normal)\n",
    "random.shuffle(list_image_pathologic)\n",
    "train_normal = list_image_normal[:int(0.7 * len(list_image_normal))+1]\n",
    "val_normal = list_image_normal[int(0.7 * len(list_image_normal))+1 : int(0.8 * len(list_image_normal))+1]\n",
    "test_normal = list_image_normal[int(0.8 * len(list_image_normal))+1:]\n",
    "train_pathologic = list_image_pathologic[:int(0.7 * len(list_image_pathologic))]\n",
    "val_pathologic = list_image_pathologic[int(0.7 * len(list_image_pathologic)) : int(0.8 * len(list_image_pathologic))]\n",
    "test_pathologic = list_image_pathologic[int(0.8 * len(list_image_pathologic)) :]\n",
    "\n",
    "list_train = train_normal + train_pathologic\n",
    "list_val = val_normal + val_pathologic\n",
    "list_test = test_normal + test_pathologic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_value = {}\n",
    "for image_path in list_image_normal+list_image_pathologic:\n",
    "    image = nib.load(image_path).get_fdata()\n",
    "    mask = nib.load(image_path.replace(\"Images\", \"Contours\")).get_fdata()\n",
    "    padded_image, crop_index_new, padded_index = pad_background(image, (128, 128))\n",
    "\n",
    "    padded_mask = pad_background_with_index(mask, crop_index_new, padded_index, (128, 128))\n",
    "\n",
    "    # calculate the number of pixel = 0, 1,2,3,4 in the mask\n",
    "    unique, counts = np.unique(padded_mask, return_counts=True)\n",
    "    for i in range(len(unique)):\n",
    "        if unique[i] in dict_value:\n",
    "            dict_value[unique[i]] += counts[i]\n",
    "        else:\n",
    "            dict_value[unique[i]] = counts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = EMIDEC_Test_Loader(list_test)\n",
    "a = data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 257, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = torch.randn(1, 5, 128, 128)\n",
    "torch.argmax(y_pred, dim=1, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1, 128, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.10942081133219704,\n",
       " 1.0: 2.335514916252746,\n",
       " 2.0: 2.714302896146349,\n",
       " 3.0: 17.46916056745279,\n",
       " 4.0: 140.11199420219833}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dict_value, calculate the weight for each class\n",
    "total = sum(dict_value.values())\n",
    "class_weight = {}\n",
    "for key in dict_value:\n",
    "    class_weight[key] = total / (dict_value[key] * 10)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 10601157, 1.0: 496673, 2.0: 427361, 3.0: 66402, 4.0: 8279}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cc0b750d954cab85cb33b9d0a0100e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='z', max=6), Output()), _dom_classes=('widget-interact',)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(z)>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize the image and mask in z axis using interact, image and mask are in one slice\n",
    "def plot_image_mask_z(image, mask, padded_image, padded_mask, z):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(image[..., z], cmap=\"gray\")\n",
    "    ax[0].set_title(\"Image uncut\")\n",
    "    ax[0].imshow(mask[..., z], cmap=\"jet\", alpha=0.3)\n",
    "    ax[1].imshow(padded_image[..., z], cmap=\"gray\")\n",
    "    ax[1].set_title(\"Image cut\")\n",
    "    ax[1].imshow(padded_mask[..., z], cmap=\"jet\", alpha=0.3)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interact(lambda z: plot_image_mask_z(image, mask, padded_image, padded_mask, z), z=(0, image.shape[-1] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomodl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
